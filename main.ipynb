{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from src.\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from src.args import ArgumentParser\n",
    "from src.build_model import build_model\n",
    "from src import utils\n",
    "from src.prepare_data import prepare_data\n",
    "from src.utils import save_ckpt_every_epoch\n",
    "from src.utils import load_ckpt\n",
    "from src.utils import print_log\n",
    "\n",
    "\n",
    "from torchmetrics import JaccardIndex as IoU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed4f9d03249afcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = ArgumentParser()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9708d7e5f827fefa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# directory for storing weights and other training related files\n",
    "training_starttime = datetime.now().strftime(\"%d_%m_%Y-%H_%M_%S-%f\")\n",
    "ckpt_dir = os.path.join(\n",
    "    args.results_dir, args.dataset, f\"{args.id}\", f\"{training_starttime}\"\n",
    ")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(ckpt_dir, \"confusion_matrices\"), exist_ok=True)\n",
    "\n",
    "with open(os.path.join(ckpt_dir, \"args.json\"), \"w\") as f:\n",
    "    json.dump(vars(args), f, sort_keys=True, indent=4)\n",
    "\n",
    "with open(os.path.join(ckpt_dir, \"argsv.txt\"), \"w\") as f:\n",
    "    f.write(\" \".join(sys.argv))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "# data preparation ---------------------------------------------------------\n",
    "data_loaders = prepare_data(args, ckpt_dir)\n",
    "\n",
    "train_loader, valid_loader, _ = data_loaders\n",
    "\n",
    "n_classes_without_void = train_loader.dataset.n_classes_without_void\n",
    "if args.class_weighting != \"None\":\n",
    "    class_weighting = train_loader.dataset.compute_class_weights(\n",
    "        weight_mode=args.class_weighting, c=args.c_for_logarithmic_weighting\n",
    "    )\n",
    "else:\n",
    "    class_weighting = np.ones(n_classes_without_void)\n",
    "# model building -----------------------------------------------------------\n",
    "model, device = build_model(args, n_classes=n_classes_without_void)\n",
    "if args.freeze > 0:\n",
    "    print(\"Freeze everything but the output layer(s).\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"out\" not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# loss, optimizer, learning rate scheduler, csvlogger  ----------\n",
    "\n",
    "# loss functions\n",
    "loss_function_train = utils.CrossEntropyLoss2d(\n",
    "    weight=class_weighting, device=device\n",
    ")\n",
    "loss_objectosphere = utils.ObjectosphereLoss()\n",
    "loss_mav = utils.OWLoss(n_classes=n_classes_without_void)\n",
    "loss_contrastive = utils.ContrastiveLoss(n_classes=n_classes_without_void)\n",
    "\n",
    "pixel_sum_valid_data = valid_loader.dataset.compute_class_weights(\n",
    "    weight_mode=\"linear\"\n",
    ")\n",
    "pixel_sum_valid_data_weighted = np.sum(pixel_sum_valid_data * class_weighting)\n",
    "loss_function_valid = utils.CrossEntropyLoss2dForValidData(\n",
    "    weight=class_weighting,\n",
    "    weighted_pixel_sum=pixel_sum_valid_data_weighted,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_loss = [loss_function_train, loss_objectosphere, loss_mav, loss_contrastive]\n",
    "val_loss = [loss_function_valid, loss_objectosphere, loss_mav, loss_contrastive]\n",
    "if not args.obj:\n",
    "    train_loss[1] = None\n",
    "    val_loss[1] = None\n",
    "if not args.mav:\n",
    "    train_loss[2] = None\n",
    "    val_loss[2] = None\n",
    "if not args.closs:\n",
    "    train_loss[3] = None\n",
    "    val_loss[3] = None\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=args.lr,\n",
    "            weight_decay=args.weight_decay,\n",
    "            betas=(0.9, 0.999),\n",
    "        )\n",
    "\n",
    "# in this script lr_scheduler.step() is only called once per epoch\n",
    "lr_scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=[i[\"lr\"] for i in optimizer.param_groups],\n",
    "    total_steps=args.epochs,\n",
    "    div_factor=25,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy=\"cos\",\n",
    "    final_div_factor=1e4,\n",
    ")\n",
    "\n",
    "# load checkpoint if parameter last_ckpt is provided\n",
    "if args.last_ckpt:\n",
    "    ckpt_path = args.last_ckpt\n",
    "    epoch_last_ckpt, best_miou, best_miou_epoch, mav_dict, std_dict = load_ckpt(\n",
    "        model, optimizer, ckpt_path, device\n",
    "    )\n",
    "    start_epoch = epoch_last_ckpt + 1\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_miou = 0\n",
    "    best_miou_epoch = 0\n",
    "\n",
    "if args.load_weights:\n",
    "    model.load_state_dict(torch.load(args.load_weights))\n",
    "\n",
    "writer = SummaryWriter(\"runs/\" + ckpt_dir.split(args.dataset)[-1])\n",
    "\n",
    "# start training -----------------------------------------------------------\n",
    "for epoch in range(int(start_epoch), args.epochs):\n",
    "    # unfreeze\n",
    "    if args.freeze == epoch and args.finetune is None:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    mean, var = train_one_epoch(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        device=device,\n",
    "        optimizer=optimizer,\n",
    "        train_loss=train_loss,\n",
    "        epoch=epoch,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        debug_mode=args.debug,\n",
    "        writer=writer,\n",
    "    )\n",
    "\n",
    "    miou = validate(\n",
    "        model=model,\n",
    "        valid_loader=valid_loader,\n",
    "        device=device,\n",
    "        val_loss=val_loss,\n",
    "        epoch=epoch,\n",
    "        debug_mode=args.debug,\n",
    "        writer=writer,\n",
    "        classes=args.num_classes,\n",
    "    )\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "    # save weights\n",
    "    if not args.overfit:\n",
    "        # save / overwrite latest weights (useful for resuming training)\n",
    "        save_ckpt_every_epoch(\n",
    "            ckpt_dir, model, optimizer, epoch, best_miou, best_miou_epoch, mean, var\n",
    "        )\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(ckpt_dir, \"epoch_\" + str(epoch) + \".pth\"),\n",
    "            )\n",
    "        if miou > best_miou:\n",
    "            best_miou = miou\n",
    "            best_miou_epoch = epoch\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(ckpt_dir, \"best_miou.pth\"),\n",
    "            )\n",
    "\n",
    "# save mavs to a pickle\n",
    "with open(\"mavs.pickle\", \"wb\") as h1:\n",
    "    pickle.dump(mean, h1, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"vars.pickle\", \"wb\") as h2:\n",
    "    pickle.dump(var, h2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Training completed \")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a7bea358dc55a9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
