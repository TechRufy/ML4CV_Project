{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea193105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:09:08.970717Z",
     "iopub.status.busy": "2025-10-09T17:09:08.970462Z",
     "iopub.status.idle": "2025-10-09T17:09:08.976550Z",
     "shell.execute_reply": "2025-10-09T17:09:08.975910Z"
    },
    "papermill": {
     "duration": 0.011507,
     "end_time": "2025-10-09T17:09:08.977743",
     "exception": false,
     "start_time": "2025-10-09T17:09:08.966236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6bbf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:09:08.984481Z",
     "iopub.status.busy": "2025-10-09T17:09:08.983977Z",
     "iopub.status.idle": "2025-10-09T17:11:20.046391Z",
     "shell.execute_reply": "2025-10-09T17:11:20.045461Z"
    },
    "papermill": {
     "duration": 131.067266,
     "end_time": "2025-10-09T17:11:20.048195",
     "exception": false,
     "start_time": "2025-10-09T17:09:08.980929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-09 17:09:09--  https://people.eecs.berkeley.edu/~hendrycks/streethazards_train.tar\r\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\r\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 9386226176 (8.7G) [application/x-tar]\r\n",
      "Saving to: ‘./data/train.tar’\r\n",
      "\r\n",
      "./data/train.tar    100%[===================>]   8.74G   149MB/s    in 74s     \r\n",
      "\r\n",
      "2025-10-09 17:10:23 (121 MB/s) - ‘./data/train.tar’ saved [9386226176/9386226176]\r\n",
      "\r\n",
      "--2025-10-09 17:10:46--  https://people.eecs.berkeley.edu/~hendrycks/streethazards_test.tar\r\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\r\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2150484992 (2.0G) [application/x-tar]\r\n",
      "Saving to: ‘./data/test.tar’\r\n",
      "\r\n",
      "./data/test.tar     100%[===================>]   2.00G   127MB/s    in 15s     \r\n",
      "\r\n",
      "2025-10-09 17:11:01 (134 MB/s) - ‘./data/test.tar’ saved [2150484992/2150484992]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir -p $DATA_DIR\n",
    "!test ! -d $DATA_DIR/train \\\n",
    "    && wget -O $DATA_DIR/train.tar https://people.eecs.berkeley.edu/~hendrycks/streethazards_train.tar \\\n",
    "    && tar -xf $DATA_DIR/train.tar -C $DATA_DIR \\\n",
    "    && rm -r $DATA_DIR/train.tar \\\n",
    "    && mv $DATA_DIR/train $DATA_DIR/streethazards_train\n",
    "!test ! -d $DATA_DIR/test \\\n",
    "    && wget -O $DATA_DIR/test.tar https://people.eecs.berkeley.edu/~hendrycks/streethazards_test.tar \\\n",
    "    && tar -xf $DATA_DIR/test.tar -C $DATA_DIR \\\n",
    "    && rm -r $DATA_DIR/test.tar\\\n",
    "    && mv $DATA_DIR/test $DATA_DIR/streethazards_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cef7d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:11:20.088723Z",
     "iopub.status.busy": "2025-10-09T17:11:20.088161Z",
     "iopub.status.idle": "2025-10-09T17:12:45.300870Z",
     "shell.execute_reply": "2025-10-09T17:12:45.300084Z"
    },
    "papermill": {
     "duration": 85.234388,
     "end_time": "2025-10-09T17:12:45.302435",
     "exception": false,
     "start_time": "2025-10-09T17:11:20.068047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\r\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.33.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.2.1)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\r\n",
      "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.15)\r\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.5.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2.4.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation-models-pytorch) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\r\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m700.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation-models-pytorch-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed9ffd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:45.448436Z",
     "iopub.status.busy": "2025-10-09T17:12:45.448130Z",
     "iopub.status.idle": "2025-10-09T17:12:57.576881Z",
     "shell.execute_reply": "2025-10-09T17:12:57.576207Z"
    },
    "papermill": {
     "duration": 12.17465,
     "end_time": "2025-10-09T17:12:57.578309",
     "exception": false,
     "start_time": "2025-10-09T17:12:45.403659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from enum import IntEnum\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Optional, Callable, Union, Tuple, Dict, List\n",
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3d2c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:57.667253Z",
     "iopub.status.busy": "2025-10-09T17:12:57.666638Z",
     "iopub.status.idle": "2025-10-09T17:12:57.673530Z",
     "shell.execute_reply": "2025-10-09T17:12:57.672771Z"
    },
    "papermill": {
     "duration": 0.052614,
     "end_time": "2025-10-09T17:12:57.674713",
     "exception": false,
     "start_time": "2025-10-09T17:12:57.622099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Source: https://github.com/hendrycks/anomaly-seg/issues/15#issuecomment-890300278\n",
    "\"\"\"\n",
    "COLORS = np.array([\n",
    "    [ 70,  70,  70],  # building     =   0,\n",
    "    [190, 153, 153],  # fence        =   1, \n",
    "    [250, 170, 160],  # other        =   2,\n",
    "    [220,  20,  60],  # pedestrian   =   3, \n",
    "    [153, 153, 153],  # pole         =   4,\n",
    "    [157, 234,  50],  # road line    =   5, \n",
    "    [128,  64, 128],  # road         =   6,\n",
    "    [244,  35, 232],  # sidewalk     =   7,\n",
    "    [107, 142,  35],  # vegetation   =   8, \n",
    "    [  0,   0, 142],  # car          =   9,\n",
    "    [102, 102, 156],  # wall         =  10, \n",
    "    [220, 220,   0],  # traffic sign =  11,\n",
    "    [ 60, 250, 240],  # anomaly      =  12,\n",
    "]) \n",
    "\n",
    "class StreetHazardsClasses(IntEnum):\n",
    "    BUILDING        = 0\n",
    "    FENCE           = 1\n",
    "    OTHER           = 2\n",
    "    PEDESTRIAN      = 3\n",
    "    POLE            = 4\n",
    "    ROAD_LINE       = 5\n",
    "    ROAD            = 6\n",
    "    SIDEWALK        = 7\n",
    "    VEGETATION      = 8\n",
    "    CAR             = 9\n",
    "    WALL            = 10\n",
    "    TRAFFIC_SIGN    = 11\n",
    "    ANOMALY         = 12\n",
    "    \n",
    "#path to streethazards dataset\n",
    "train_odgt_file = f\"{DATA_DIR}/streethazards_train/train.odgt\"\n",
    "val_odgt_file = f\"{DATA_DIR}/streethazards_train/validation.odgt\"\n",
    "test_odgt_file = f\"{DATA_DIR}/streethazards_test/test.odgt\"\n",
    "\n",
    "COMPUTE_MEAN_STD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f4c36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:57.763658Z",
     "iopub.status.busy": "2025-10-09T17:12:57.763391Z",
     "iopub.status.idle": "2025-10-09T17:12:57.771417Z",
     "shell.execute_reply": "2025-10-09T17:12:57.770515Z"
    },
    "papermill": {
     "duration": 0.054602,
     "end_time": "2025-10-09T17:12:57.772983",
     "exception": false,
     "start_time": "2025-10-09T17:12:57.718381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StreetHazardsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the StreetHazards inliner dataset.\n",
    "\n",
    "    This dataset reads image and segmentation label paths from a `.odgt` file,\n",
    "    applies optional resizing and spatial transformations, and returns\n",
    "    dictionary-style samples with normalized image tensors and label tensors.\n",
    "\n",
    "    Args:\n",
    "        odgt_file (str): Path to the `.odgt` file containing image and label metadata.\n",
    "        image_resize (Tuple[int, int], optional): Target size to resize images and labels. \n",
    "        spatial_transforms (Callable, optional): Optional transformation function applied to both images and labels.\n",
    "        mean_std (Tuple[List[float], List[float]], optional): Mean and standard deviation for image normalization.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        odgt_file: str,\n",
    "        image_resize: Tuple[int, int] = (512, 896),\n",
    "        spatial_transforms: Optional[Callable] = None,\n",
    "        mean_std: Tuple[List[float], List[float]] = None\n",
    "    ):\n",
    "\n",
    "        self.spatial_transforms = spatial_transforms\n",
    "        self.mean_std = mean_std\n",
    "        self.image_resize = image_resize\n",
    "\n",
    "        with open(odgt_file, \"r\") as f:\n",
    "            odgt_data = json.load(f)\n",
    "        \n",
    "\n",
    "        self.paths = [\n",
    "            {\n",
    "                \"image\": os.path.join(Path(odgt_file).parent, data[\"fpath_img\"]),\n",
    "                \"labels\": os.path.join(Path(odgt_file).parent, data[\"fpath_segm\"]),\n",
    "            }\n",
    "            for data in odgt_data \n",
    "        ]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        image = Image.open(self.paths[idx][\"image\"]).convert(\"RGB\")\n",
    "        labels = Image.open(self.paths[idx][\"labels\"])\n",
    "\n",
    "        if self.image_resize:\n",
    "            image = transforms.Resize(self.image_resize, transforms.InterpolationMode.BILINEAR)(image)\n",
    "            labels = transforms.Resize(self.image_resize, transforms.InterpolationMode.NEAREST)(labels)\n",
    "            \n",
    "        if self.spatial_transforms:\n",
    "            image, labels  = self.spatial_transforms(image, labels)         \n",
    "\n",
    "        #to_tensor\n",
    "        image = transforms.ToTensor()(image)\n",
    "        labels = torch.as_tensor(transforms.functional.pil_to_tensor(labels), dtype=torch.int64) - 1\n",
    "        \n",
    "        labels = labels.squeeze(0)\n",
    "        \n",
    "        if self.mean_std:\n",
    "            image = transforms.Normalize(mean = self.mean_std[0], std = self.mean_std[1])(image)\n",
    "\n",
    "        return {'image' : image, 'labels' : labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8751cd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:57.861276Z",
     "iopub.status.busy": "2025-10-09T17:12:57.860744Z",
     "iopub.status.idle": "2025-10-09T17:12:57.871700Z",
     "shell.execute_reply": "2025-10-09T17:12:57.870967Z"
    },
    "papermill": {
     "duration": 0.056354,
     "end_time": "2025-10-09T17:12:57.872975",
     "exception": false,
     "start_time": "2025-10-09T17:12:57.816621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_one_hot_prototypes_torch(num_known_classes: int, t_value: float = 3.0, device: str = 'cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generates one-hot prototypes as a PyTorch tensor for a given number of known classes.\n",
    "    Each prototype is a vector where only the element corresponding\n",
    "    to its class index has the 't_value', and all other elements are 0.\n",
    "\n",
    "    Args:\n",
    "        num_known_classes (int): The total number of known (in-distribution) classes.\n",
    "                                 This also determines the dimensionality of each prototype vector.\n",
    "        t_value (float): The non-zero value at the class's specific index in the prototype.\n",
    "                         As specified in the paper, this is often 3.0.\n",
    "        device (str): The device on which to create the tensor ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 2D PyTorch tensor where each row is a prototype vector.\n",
    "                      The shape will be (num_known_classes, num_known_classes).\n",
    "    \"\"\"\n",
    "    if not isinstance(num_known_classes, int) or num_known_classes <= 0:\n",
    "        raise ValueError(\"num_known_classes must be a positive integer.\")\n",
    "    if not isinstance(t_value, (int, float)):\n",
    "        raise ValueError(\"t_value must be a numeric type.\")\n",
    "    if device not in ['cpu', 'cuda']:\n",
    "        raise ValueError(\"device must be 'cpu' or 'cuda'.\")\n",
    "\n",
    "    # Create a tensor of zeros\n",
    "    prototypes = torch.zeros((num_known_classes, num_known_classes), dtype=torch.float32, device=device)\n",
    "\n",
    "    # Fill the diagonal with t_value to create one-hot prototypes\n",
    "    for i in range(num_known_classes):\n",
    "        prototypes[i, i] = t_value\n",
    "        \n",
    "    # An even more concise way using torch.eye (Identity matrix)\n",
    "    # prototypes = torch.eye(num_known_classes, dtype=torch.float32, device=device) * t_value\n",
    "\n",
    "    return prototypes\n",
    "\n",
    "Prototype  = create_one_hot_prototypes_torch(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85dc5a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:57.962168Z",
     "iopub.status.busy": "2025-10-09T17:12:57.961450Z",
     "iopub.status.idle": "2025-10-09T17:12:57.968553Z",
     "shell.execute_reply": "2025-10-09T17:12:57.967963Z"
    },
    "papermill": {
     "duration": 0.052866,
     "end_time": "2025-10-09T17:12:57.969633",
     "exception": false,
     "start_time": "2025-10-09T17:12:57.916767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class DMLNetFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, encoder_name, encoder_weights, num_feature_channels, activation):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.model = smp.DeepLabV3Plus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            classes=num_feature_channels, # This sets the output channels of the segmentation_head if kept\n",
    "            activation=activation # Usually 'None' for the main head, but for features it might not matter directly\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Option 2 is safer and more robust.\n",
    "        # First, we disable the original segmentation head as you did.\n",
    "        self.original_segmentation_head = self.model.segmentation_head # Store it if needed\n",
    "        self.model.segmentation_head = torch.nn.Identity() # Remove the final head\n",
    "\n",
    "        # --- CORRECTION START ---\n",
    "        # To get the decoder's actual output channels, we need a dummy forward pass\n",
    "        # through just the encoder and decoder.\n",
    "        \n",
    "        # Temporarily detach the module to make a dummy pass if needed,\n",
    "        # but in __init__, we can usually just do a conceptual forward.\n",
    "        # However, to be absolutely safe and get the runtime channel count:\n",
    "        \n",
    "        # Create a dummy input to trace the decoder output channels\n",
    "        # Assuming typical RGB input (3 channels) and arbitrary spatial dimensions\n",
    "        dummy_input = torch.randn(2, 3, 256, 256) \n",
    "        \n",
    "        # Pass through encoder\n",
    "        encoder_features_dummy = self.model.encoder(dummy_input)\n",
    "        \n",
    "        # Pass through decoder to get its output channels\n",
    "        decoder_output_dummy = self.model.decoder(encoder_features_dummy)\n",
    "        \n",
    "        # Extract the channel dimension from the dummy output\n",
    "        decoder_actual_out_channels = decoder_output_dummy.shape[1]\n",
    "        # --- CORRECTION END ---\n",
    "\n",
    "        # Add a 1x1 convolution to project the decoder's output to the desired num_feature_channels.\n",
    "        self.feature_projection = torch.nn.Conv2d(\n",
    "            in_channels=decoder_actual_out_channels,\n",
    "            out_channels=num_feature_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_spatial_size = x.shape[2:]\n",
    "        # The encoder outputs a list of feature maps at different resolutions\n",
    "        encoder_features = self.model.encoder(x)\n",
    "        \n",
    "        # The decoder takes these features and produces a high-resolution feature map.\n",
    "        # This output will typically have the same spatial dimensions as the input 'x'\n",
    "        # (due to DeepLabV3+ decoder's upsampling) but with its default channel count.\n",
    "        decoder_output = self.model.decoder(encoder_features)\n",
    "        \n",
    "        # Project the decoder's output to the desired number of feature channels\n",
    "        projected_features = self.feature_projection(decoder_output)\n",
    "\n",
    "        final_features = torch.nn.functional.interpolate(\n",
    "            projected_features, \n",
    "            size=input_spatial_size, \n",
    "            mode='bilinear', \n",
    "            align_corners=False # Set to True for pixel alignment if needed, but False is common\n",
    "        )\n",
    "        \n",
    "        # These `final_features` are your f(X; θf)i,j with num_feature_channels.\n",
    "        return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0eb16cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:58.059424Z",
     "iopub.status.busy": "2025-10-09T17:12:58.059140Z",
     "iopub.status.idle": "2025-10-09T17:12:58.066254Z",
     "shell.execute_reply": "2025-10-09T17:12:58.065636Z"
    },
    "papermill": {
     "duration": 0.053164,
     "end_time": "2025-10-09T17:12:58.067351",
     "exception": false,
     "start_time": "2025-10-09T17:12:58.014187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiscriminativeCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, prototypes: torch.Tensor,lambda_weight):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.prototypes = prototypes.to(device)\n",
    "        self.lambda_weight = lambda_weight\n",
    "\n",
    "    def forward(self, pixel_features: torch.Tensor, target_labels: torch.Tensor):\n",
    "        # pixel_features: (B, D, H, W)\n",
    "        # target_labels: (B, H, W)\n",
    "\n",
    "        # Reshape pixel_features for easier broadcasting with prototypes\n",
    "        # (B, D, H, W) -> (B, H, W, D)\n",
    "        pixel_features_reshaped = pixel_features.permute(0, 2, 3, 1) # (B, H, W, D)\n",
    "\n",
    "        # Expand target_labels to match the feature dimension for indexing prototypes\n",
    "        # (B, H, W) -> (B, H, W, D)\n",
    "        prototypes_target = self.prototypes[target_labels] # This should now be (B, H, W, D)\n",
    "\n",
    "        # --- Numerator (Attractive Force) ---\n",
    "        # ||f(X; θf)i,j – mY i,j ||²\n",
    "        # (B, H, W, D) - (B, H, W, D) -> (B, H, W, D)\n",
    "        difference_numerator = pixel_features_reshaped - prototypes_target\n",
    "        # (B, H, W, D) -> (B, H, W)\n",
    "        squared_diff_numerator = torch.sum(difference_numerator.pow(2), dim=-1)\n",
    "        exp_squared_diff_numerator = torch.exp(-squared_diff_numerator)\n",
    "\n",
    "        # --- Denominator (Repulsive Force) ---\n",
    "        # Σk=1 to N ( exp(-||f(X; θf)i,j – mk ||²) )\n",
    "        # To compute this, we need to calculate the squared difference for ALL prototypes\n",
    "        # and then sum their exponentials.\n",
    "\n",
    "        # Expand pixel_features to compare with all prototypes: (B, H, W, 1, D)\n",
    "        pixel_features_expanded = pixel_features_reshaped.unsqueeze(-2) # (B, H, W, 1, D)\n",
    "\n",
    "        # Expand prototypes to compare with all pixels: (1, 1, 1, N, D)\n",
    "        # self.prototypes has shape (N, D)\n",
    "        prototypes_expanded = self.prototypes.unsqueeze(0).unsqueeze(0).unsqueeze(0) # (1, 1, 1, N, D)\n",
    "\n",
    "        # Calculate difference between each pixel feature and ALL prototypes\n",
    "        # (B, H, W, 1, D) - (1, 1, 1, N, D) -> (B, H, W, N, D)\n",
    "        all_prototypes_differences = pixel_features_expanded - prototypes_expanded\n",
    "\n",
    "        # Square and sum across the feature dimension (D)\n",
    "        # (B, H, W, N, D) -> (B, H, W, N)\n",
    "        squared_diff_all_prototypes = torch.sum(all_prototypes_differences.pow(2), dim=-1)\n",
    "\n",
    "        # Exponentiate\n",
    "        # (B, H, W, N)\n",
    "        exp_squared_diff_all_prototypes = torch.exp(-squared_diff_all_prototypes)\n",
    "\n",
    "        # Sum across the prototype dimension (N) to get the denominator\n",
    "        # (B, H, W, N) -> (B, H, W)\n",
    "        denominator = torch.sum(exp_squared_diff_all_prototypes, dim=-1)\n",
    "\n",
    "        # --- Calculate Pt(Xi,j) (Equation 2) ---\n",
    "        # (B, H, W) / (B, H, W) -> (B, H, W)\n",
    "        pt_values = exp_squared_diff_numerator / (denominator + 1e-8) # Add small epsilon for stability\n",
    "\n",
    "        # --- Calculate LDCE (Equation 3) ---\n",
    "        # LDCE = -log(pt_values) for target classes\n",
    "        # This requires masking based on target_labels or using the pt_values directly\n",
    "        # The equation shows sum over i,j of -log(numerator/denominator) where numerator corresponds to Y_i,j\n",
    "\n",
    "        # Assuming Y_i,j is 1 for the target class at that pixel and 0 otherwise.\n",
    "        # This is essentially -log(Pt(Xi,j)) for the correct class, summed over all pixels.\n",
    "        ldce_loss = -torch.log(pt_values + 1e-8) # Add small epsilon for stability\n",
    "        ldce_loss = torch.sum(ldce_loss) # Or torch.sum() depending on how you want to aggregate\n",
    "\n",
    "        Lvl_loss = torch.sum(difference_numerator.pow(2))\n",
    "        \n",
    "        \n",
    "        return ldce_loss + self.lambda_weight * Lvl_loss\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49dcea1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:58.155838Z",
     "iopub.status.busy": "2025-10-09T17:12:58.155182Z",
     "iopub.status.idle": "2025-10-09T17:12:58.260629Z",
     "shell.execute_reply": "2025-10-09T17:12:58.259820Z"
    },
    "papermill": {
     "duration": 0.15131,
     "end_time": "2025-10-09T17:12:58.262186",
     "exception": false,
     "start_time": "2025-10-09T17:12:58.110876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_resize = (512, 896)\n",
    "\n",
    "if COMPUTE_MEAN_STD:\n",
    "    mean_streethazards, std_streethazards = compute_mean_std_channels(StreetHazardsDataset(odgt_file= train_odgt_file,\n",
    "                                                                                           image_resize = shape_resize,\n",
    "                                                                                           spatial_transforms=None,\n",
    "                                                                                           mean_std=None))\n",
    "else:\n",
    "    mean_streethazards, std_streethazards = [0.3302, 0.3459, 0.373], [0.1595, 0.1577, 0.1712]\n",
    "\n",
    "spatial_transforms = transforms.v2.Compose([\n",
    "    transforms.v2.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "train_dataset = StreetHazardsDataset(\n",
    "    odgt_file= train_odgt_file,\n",
    "    image_resize = shape_resize,\n",
    "    spatial_transforms=spatial_transforms,\n",
    "    mean_std=(mean_streethazards, std_streethazards)\n",
    ")\n",
    "\n",
    "val_dataset = StreetHazardsDataset(\n",
    "    odgt_file= val_odgt_file,\n",
    "    image_resize = shape_resize,\n",
    "    spatial_transforms=None,\n",
    "    mean_std=(mean_streethazards, std_streethazards)\n",
    ")\n",
    "\n",
    "test_dataset = StreetHazardsDataset(\n",
    "    odgt_file= test_odgt_file,\n",
    "    image_resize = shape_resize,\n",
    "    spatial_transforms=None,\n",
    "    mean_std=(mean_streethazards, std_streethazards)\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_dl = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "test_dl = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9d1bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:12:58.351413Z",
     "iopub.status.busy": "2025-10-09T17:12:58.350838Z",
     "iopub.status.idle": "2025-10-09T17:13:00.525237Z",
     "shell.execute_reply": "2025-10-09T17:13:00.524598Z"
    },
    "papermill": {
     "duration": 2.220387,
     "end_time": "2025-10-09T17:13:00.526642",
     "exception": false,
     "start_time": "2025-10-09T17:12:58.306255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512acee43f6a406b97f28fc6f0cb9455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f76b628f4394e21b824159d451f3d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Esempio di utilizzo:\n",
    "encoder_name = \"resnet18\"\n",
    "encoder_weights = \"imagenet\"\n",
    "num_known_classes = 13 # Numero di classi per cui i prototipi sono one-hot\n",
    "t_value = 3.0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Inizializza il feature extractor\n",
    "feature_extractor = DMLNetFeatureExtractor(\n",
    "    encoder_name=encoder_name,\n",
    "    encoder_weights=encoder_weights,\n",
    "    num_feature_channels=num_known_classes,\n",
    "    activation=None\n",
    ").to(device)\n",
    "model_optimizer = torch.optim.Adam(feature_extractor.parameters(), lr=0.001)\n",
    "\n",
    "def train(num_epochs,model,train_loader,lambda_weight) -> None:\n",
    "        \n",
    "        for epoch in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            losses = []\n",
    "\n",
    "            for batch in train_loader: \n",
    "\n",
    "                    \n",
    "                imgs = batch['image'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                logits = model(imgs)\n",
    "                \n",
    "                lossClass = DiscriminativeCrossEntropyLoss(Prototype,lambda_weight)\n",
    "\n",
    "                \n",
    "                loss = lossClass(logits,labels)\n",
    "                            \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                model_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                model_optimizer.step()\n",
    "            \n",
    "                del loss\n",
    "                \n",
    "\n",
    "            l = sum(losses) / len(losses)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}\", end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68486070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T17:13:00.615158Z",
     "iopub.status.busy": "2025-10-09T17:13:00.614847Z",
     "iopub.status.idle": "2025-10-09T17:58:53.380531Z",
     "shell.execute_reply": "2025-10-09T17:58:53.379581Z"
    },
    "papermill": {
     "duration": 2752.843729,
     "end_time": "2025-10-09T17:58:53.414445",
     "exception": false,
     "start_time": "2025-10-09T17:13:00.570716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [04:35<41:22, 275.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [09:11<36:43, 275.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [13:46<32:07, 275.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [18:21<27:32, 275.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [22:56<22:56, 275.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [27:31<18:21, 275.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [32:07<13:45, 275.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [36:42<09:10, 275.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [41:17<04:35, 275.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [45:52<00:00, 275.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(10,feature_extractor,train_dl,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f88ed",
   "metadata": {
    "papermill": {
     "duration": 0.044551,
     "end_time": "2025-10-09T17:58:53.504537",
     "exception": false,
     "start_time": "2025-10-09T17:58:53.459986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2990.595049,
   "end_time": "2025-10-09T17:58:55.474784",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-09T17:09:04.879735",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "084ffaefd4cd45a8a87360f694dae995": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "22d4e4a42be54ae589149a18916f34a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e3ade5a25f44b4e91fba4122b4dbab5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "512acee43f6a406b97f28fc6f0cb9455": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc306c64b74a414991e9282f3bb7f4c5",
        "IPY_MODEL_ab53fd45cb9e447686660d630a4f536e",
        "IPY_MODEL_523f51769e264e1586be6d8f60482eb8"
       ],
       "layout": "IPY_MODEL_a53e2323822241faa53751d9ef42b89e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "523f51769e264e1586be6d8f60482eb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e932c3739af0477d9f06390924387bfc",
       "placeholder": "​",
       "style": "IPY_MODEL_6c6220daafb04b5daaca54d456714471",
       "tabbable": null,
       "tooltip": null,
       "value": " 156/156 [00:00&lt;00:00, 17.5kB/s]"
      }
     },
     "665a3ffa1a7040ce96a8e9509afd7c8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c6220daafb04b5daaca54d456714471": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6d05334e930c40ab9263832a750ff958": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e4b93dcb0644c0a9dca38e9f4c9780a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6f76b628f4394e21b824159d451f3d4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ab8e619803f44d04b01b728371614eeb",
        "IPY_MODEL_80efd61fbd174a94be265896888c9558",
        "IPY_MODEL_b5a51676e7ac428c924603897cb59dac"
       ],
       "layout": "IPY_MODEL_a2535c22df714f958bb688705de2d4d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7b3908228f7f4614b1fd381ecea287ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80efd61fbd174a94be265896888c9558": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22d4e4a42be54ae589149a18916f34a4",
       "max": 46805552.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed7ea076709942bfbcf9a949d7fc2b95",
       "tabbable": null,
       "tooltip": null,
       "value": 46805552.0
      }
     },
     "a2535c22df714f958bb688705de2d4d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a53e2323822241faa53751d9ef42b89e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9c19aec1de14d8097ea320d6d2c29eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab53fd45cb9e447686660d630a4f536e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b179d3c911b644f8ab298360549ee9da",
       "max": 156.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2e3ade5a25f44b4e91fba4122b4dbab5",
       "tabbable": null,
       "tooltip": null,
       "value": 156.0
      }
     },
     "ab8e619803f44d04b01b728371614eeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_665a3ffa1a7040ce96a8e9509afd7c8d",
       "placeholder": "​",
       "style": "IPY_MODEL_6e4b93dcb0644c0a9dca38e9f4c9780a",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b179d3c911b644f8ab298360549ee9da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5a51676e7ac428c924603897cb59dac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d05334e930c40ab9263832a750ff958",
       "placeholder": "​",
       "style": "IPY_MODEL_a9c19aec1de14d8097ea320d6d2c29eb",
       "tabbable": null,
       "tooltip": null,
       "value": " 46.8M/46.8M [00:01&lt;00:00, 45.6MB/s]"
      }
     },
     "cc306c64b74a414991e9282f3bb7f4c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7b3908228f7f4614b1fd381ecea287ed",
       "placeholder": "​",
       "style": "IPY_MODEL_084ffaefd4cd45a8a87360f694dae995",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "e932c3739af0477d9f06390924387bfc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed7ea076709942bfbcf9a949d7fc2b95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
